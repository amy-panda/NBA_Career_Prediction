# NBA Career Prediction
Following the Cross-Industry Standard Process for Data Mining (CRISP-DM) methodology, this project undertook data processing and developed multiple classification models to forecast whether a rookie player would continue playing in the NBA league for at least five years. These models encompassed Logistic Regression, Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest, AdaBoost, and XGBoost. The top-performing classifiers, Logistic Regression and XGBoost, were identified based on key performance metrics, including ROC-AUC scores and Confusion matrix.

## ğŸ¤ Contributors
- Amy Yang
- Chanthru Vimalasri
- Yatindra Vegunta


## ğŸ—¼ Project Organization

    â”œâ”€â”€ README.md          <- README file with project details.
    |
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ external       <- Data from third party sources.
    â”‚Â Â  â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚Â Â  â”œâ”€â”€ processed      <- Including training and validation sets.
    â”‚Â Â  â””â”€â”€ raw            <- Including 2022_train.csv and 2022_test.csv files.
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Including the data preprocessing and two best models. 
    â”‚
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚Â Â  â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
    â”‚
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â”œâ”€â”€ setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    |
    |
    â””â”€â”€ src                <- Source code for use in this project.
    Â Â   â”œâ”€â”€ __init__.py    <- Makes src a Python module
        â”‚
    Â Â   â”œâ”€â”€ data           <- Scripts to download or generate data
    Â Â   â”‚Â Â  â””â”€â”€ sets.py  
        â”‚
    Â Â   â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    Â Â   â”‚Â Â  â””â”€â”€ build_features.py
        â”‚
        |
        â””â”€â”€ models         <- Scripts to train models and then use trained models to make
            â”‚                 predictions
    Â Â   Â Â   â”œâ”€â”€ null.py
    Â Â  Â  Â   â””â”€â”€ performance.py
    
Note: The project organisation above is adapted with the [cookiecutter data science project template](https://drivendata.github.io/cookiecutter-data-science/).


## ğŸ›  Tools and Techniques
- Feature engineering
- Imputation methods such as single imputation by using mean/median, multiple imputation and Nearest neighbour imputation
- Imbalance data treatment including oversampling, undersampling, STOME and hyperparameter setting
- Model training with the packages including [lazypredict](https://pypi.org/project/lazypredict/) and [scikit-learn](https://pypi.org/project/scikit-learn/)
- Hyperparameter tuning with random search, grid search and automatic search using the Hyperopt package
- Model evaluation with ROC-AUC score and Confusion Matrix plot




## â„¹ï¸ Data Source

Kaggle Competition [[UTS AdvDSI 2022-11] NBA Career Prediction](https://www.kaggle.com/competitions/uts-advdsi-2022-11-nba-career-prediction/overview)




