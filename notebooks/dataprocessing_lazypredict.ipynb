{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Model Performance Comparison with Lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file and save into data\n",
    "data=pd.read_csv('../data/raw/2022_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>80</td>\n",
       "      <td>24.30</td>\n",
       "      <td>7.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.40</td>\n",
       "      <td>45.70</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>22.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>72.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>75</td>\n",
       "      <td>21.80</td>\n",
       "      <td>10.50</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.90</td>\n",
       "      <td>55.10</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>67.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>85</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.50</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.20</td>\n",
       "      <td>34.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>75.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>63</td>\n",
       "      <td>19.10</td>\n",
       "      <td>8.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.70</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>23.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.50</td>\n",
       "      <td>66.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>63</td>\n",
       "      <td>17.80</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>50.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  GP   MIN   PTS  FGM  FGA   FG%  3P Made   3PA   3P%  FTM  FTA   FT%  \\\n",
       "0  3799  80 24.30  7.80 3.00 6.40 45.70     0.10  0.30 22.60 2.00 2.90 72.10   \n",
       "1  3800  75 21.80 10.50 4.20 7.90 55.10    -0.30 -1.00 34.90 2.40 3.60 67.80   \n",
       "2  3801  85 19.10  4.50 1.90 4.50 42.80     0.40  1.20 34.30 0.40 0.60 75.70   \n",
       "3  3802  63 19.10  8.20 3.50 6.70 52.50     0.30  0.80 23.70 0.90 1.50 66.90   \n",
       "4  3803  63 17.80  3.70 1.70 3.40 50.80     0.50  1.40 13.70 0.20 0.50 54.00   \n",
       "\n",
       "   OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.20  2.00 3.80 3.20 1.10 0.20 1.60            1  \n",
       "1  3.60  3.70 6.60 0.70 0.50 0.60 1.40            1  \n",
       "2  0.60  1.80 2.40 0.80 0.40 0.20 0.60            1  \n",
       "3  0.80  2.00 3.00 1.80 0.40 0.10 1.90            1  \n",
       "4  2.40  2.70 4.90 0.40 0.40 0.60 0.70            1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of data and all the columns\n",
    "pd.set_option('max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id           8000 non-null   int64  \n",
      " 1   GP           8000 non-null   int64  \n",
      " 2   MIN          8000 non-null   float64\n",
      " 3   PTS          8000 non-null   float64\n",
      " 4   FGM          8000 non-null   float64\n",
      " 5   FGA          8000 non-null   float64\n",
      " 6   FG%          8000 non-null   float64\n",
      " 7   3P Made      8000 non-null   float64\n",
      " 8   3PA          8000 non-null   float64\n",
      " 9   3P%          8000 non-null   float64\n",
      " 10  FTM          8000 non-null   float64\n",
      " 11  FTA          8000 non-null   float64\n",
      " 12  FT%          8000 non-null   float64\n",
      " 13  OREB         8000 non-null   float64\n",
      " 14  DREB         8000 non-null   float64\n",
      " 15  REB          8000 non-null   float64\n",
      " 16  AST          8000 non-null   float64\n",
      " 17  STL          8000 non-null   float64\n",
      " 18  BLK          8000 non-null   float64\n",
      " 19  TOV          8000 non-null   float64\n",
      " 20  TARGET_5Yrs  8000 non-null   int64  \n",
      "dtypes: float64(18), int64(3)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Display the summary of columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the summary above, none of the columns in dataframe has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 21)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dimensions(shape) of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>8000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7798.50</td>\n",
       "      <td>62.78</td>\n",
       "      <td>18.58</td>\n",
       "      <td>7.27</td>\n",
       "      <td>2.81</td>\n",
       "      <td>6.23</td>\n",
       "      <td>44.61</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.82</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.95</td>\n",
       "      <td>71.37</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.55</td>\n",
       "      <td>17.12</td>\n",
       "      <td>8.94</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3799.00</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>21.30</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>-38.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-13.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-17.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5798.75</td>\n",
       "      <td>51.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.60</td>\n",
       "      <td>40.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7798.50</td>\n",
       "      <td>63.00</td>\n",
       "      <td>16.80</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>44.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>19.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>71.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9798.25</td>\n",
       "      <td>74.00</td>\n",
       "      <td>23.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>3.70</td>\n",
       "      <td>8.10</td>\n",
       "      <td>48.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>30.60</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.60</td>\n",
       "      <td>77.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.90</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11798.00</td>\n",
       "      <td>123.00</td>\n",
       "      <td>73.80</td>\n",
       "      <td>34.20</td>\n",
       "      <td>13.10</td>\n",
       "      <td>28.90</td>\n",
       "      <td>67.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4.70</td>\n",
       "      <td>82.10</td>\n",
       "      <td>8.10</td>\n",
       "      <td>11.10</td>\n",
       "      <td>168.90</td>\n",
       "      <td>5.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.90</td>\n",
       "      <td>12.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18.90</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id      GP     MIN     PTS     FGM     FGA     FG%  3P Made  \\\n",
       "count  8000.00 8000.00 8000.00 8000.00 8000.00 8000.00 8000.00  8000.00   \n",
       "mean   7798.50   62.78   18.58    7.27    2.81    6.23   44.61     0.26   \n",
       "std    2309.55   17.12    8.94    4.32    1.69    3.58    6.16     0.38   \n",
       "min    3799.00   -8.00    2.90    0.80    0.30    0.80   21.30    -1.10   \n",
       "25%    5798.75   51.00   12.00    4.10    1.60    3.60   40.40     0.00   \n",
       "50%    7798.50   63.00   16.80    6.30    2.40    5.40   44.40     0.30   \n",
       "75%    9798.25   74.00   23.50    9.50    3.70    8.10   48.70     0.50   \n",
       "max   11798.00  123.00   73.80   34.20   13.10   28.90   67.20     1.70   \n",
       "\n",
       "          3PA     3P%     FTM     FTA     FT%    OREB    DREB     REB     AST  \\\n",
       "count 8000.00 8000.00 8000.00 8000.00 8000.00 8000.00 8000.00 8000.00 8000.00   \n",
       "mean     0.82   19.58    1.39    1.95   71.37    1.08    2.17    3.25    1.62   \n",
       "std      1.06   16.00    0.93    1.25   10.43    0.79    1.39    2.09    1.36   \n",
       "min     -3.10  -38.50    0.00    0.00  -13.30    0.00    0.20    0.30    0.00   \n",
       "25%      0.10    8.40    0.70    1.00   65.00    0.50    1.10    1.70    0.70   \n",
       "50%      0.80   19.50    1.20    1.70   71.40    0.90    1.90    2.80    1.30   \n",
       "75%      1.50   30.60    1.90    2.60   77.50    1.50    2.90    4.30    2.20   \n",
       "max      4.70   82.10    8.10   11.10  168.90    5.50   11.00   15.90   12.80   \n",
       "\n",
       "          STL     BLK     TOV  TARGET_5Yrs  \n",
       "count 8000.00 8000.00 8000.00      8000.00  \n",
       "mean     0.65    0.25    1.26         0.83  \n",
       "std      0.41    0.82    0.72         0.37  \n",
       "min      0.00  -17.90    0.10         0.00  \n",
       "25%      0.30    0.10    0.70         1.00  \n",
       "50%      0.60    0.20    1.10         1.00  \n",
       "75%      0.90    0.40    1.60         1.00  \n",
       "max      3.60   18.90    5.30         1.00  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unreasonable data based on descriptive summary**\n",
    "- Games played cannot be negative\n",
    "- 3P, 3PA and 3P% Made cannot be negative\n",
    "- FT% can not be negative and cannot be over 100%\n",
    "- BLK can not be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6669\n",
       "0    1331\n",
       "Name: TARGET_5Yrs, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of records in two classes\n",
    "data['TARGET_5Yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Display the counts of target value\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.countplot(x='TARGET_5Yrs', data=data, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Split Train and Test Sets for Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data and save it into a variable data_cleaned\n",
    "data_cleaned=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the id column\n",
    "data_cleaned.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column 'TARGET_5Yrs' and save it into variable called target\n",
    "target=data_cleaned.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function scaler_split_train_test from data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sys.path[1]\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the scaler data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val=split_train_test(df=data_cleaned,target=target,test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function save_sets from sets and save the sets into the folder data/processed\n",
    "from src.data.sets import save_sets\n",
    "save_sets(X_train, y_train, X_val, y_val, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function load_sets from sets and load the sets from data/processed\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statistics\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mode of the target variable from the training set\n",
    "y_mode=mode(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array called y_base of dimensions (len(y_train), 1) filled with the mode value\n",
    "y_base=np.full((len(y_train),1),y_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Training: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Import the function print_class_perf from models.performance and display the ROC-AUC score\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_train,y_base,set_name='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lazypredict package\n",
    "import lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LazyClassifier from lazypredict.Supervised\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:15<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit the Lazyclassifier model based on train set and predict the validation set\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None,random_state=8)\n",
    "models,predictions = clf.fit(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "GaussianNB                         0.58               0.63     0.69      0.64   \n",
       "BernoulliNB                        0.64               0.63     0.68      0.68   \n",
       "QuadraticDiscriminantAnalysis      0.77               0.60     0.67      0.77   \n",
       "DecisionTreeClassifier             0.75               0.56     0.56      0.76   \n",
       "ExtraTreeClassifier                0.74               0.55     0.55      0.75   \n",
       "KNeighborsClassifier               0.82               0.54     0.61      0.78   \n",
       "BaggingClassifier                  0.81               0.54     0.62      0.78   \n",
       "LabelSpreading                     0.75               0.54     0.63      0.75   \n",
       "LabelPropagation                   0.75               0.53     0.62      0.75   \n",
       "LGBMClassifier                     0.83               0.52     0.67      0.78   \n",
       "RandomForestClassifier             0.84               0.52     0.66      0.78   \n",
       "XGBClassifier                      0.81               0.52     0.64      0.77   \n",
       "AdaBoostClassifier                 0.84               0.52     0.69      0.78   \n",
       "ExtraTreesClassifier               0.84               0.52     0.67      0.78   \n",
       "LinearDiscriminantAnalysis         0.84               0.52     0.70      0.78   \n",
       "CalibratedClassifierCV             0.84               0.51     0.71      0.77   \n",
       "LogisticRegression                 0.83               0.51     0.71      0.77   \n",
       "DummyClassifier                    0.84               0.50     0.50      0.77   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "GaussianNB                           0.02  \n",
       "BernoulliNB                          0.03  \n",
       "QuadraticDiscriminantAnalysis        0.03  \n",
       "DecisionTreeClassifier               0.09  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "KNeighborsClassifier                 0.19  \n",
       "BaggingClassifier                    0.50  \n",
       "LabelSpreading                       3.89  \n",
       "LabelPropagation                     2.58  \n",
       "LGBMClassifier                       0.28  \n",
       "RandomForestClassifier               1.30  \n",
       "XGBClassifier                        0.50  \n",
       "AdaBoostClassifier                   0.44  \n",
       "ExtraTreesClassifier                 0.76  \n",
       "LinearDiscriminantAnalysis           0.07  \n",
       "CalibratedClassifierCV               1.81  \n",
       "LogisticRegression                   0.10  \n",
       "DummyClassifier                      0.01  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the metrics for different classifiers\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lazypredict_raw.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Import dump from joblib and save the fitted model into the folder models as a file called lazypredict_raw\n",
    "from joblib import dump \n",
    "\n",
    "dump(clf,  '../models/lazypredict_raw.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - Dropping Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data and save it into a variable data_cleaned\n",
    "data_cleaned=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the id column\n",
    "data_cleaned.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows where Games played are below or equal to 0\n",
    "len(data_cleaned[(data_cleaned['GP']<=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the small number, remove the 2 records when the column Games played is negative\n",
    "data_cleaned.drop(data_cleaned[data_cleaned['GP']<=0].index,inplace=True)\n",
    "\n",
    "# Method 2\n",
    "# data_cleaned=data_cleaned[(data_cleaned['GP']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1628 rows where '3P Made' column is negative.\n",
      "There are 1657 rows where '3PA' column is negative.\n",
      "There are 878 rows where '3P%' column is negative.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows where the columns of 3P Made, 3PA and 3P% are negative\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['3P Made']<0])} rows where '3P Made' column is negative.\")\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['3PA']<0])} rows where '3PA' column is negative.\")\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['3P%']<0])} rows where '3P%' column is negative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the significant number of rows, the columns of '3P Made', '3PA' and '3P%' are removed from the dataset\n",
    "data_cleaned.drop(['3P Made','3PA','3P%'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 rows where 'FT%' column is negative.\n",
      "There are 58 rows where 'FT%' column is over 100%.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows where FT% is negative or over 100%\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['FT%']<0])} rows where 'FT%' column is negative.\")\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['FT%']>100])} rows where 'FT%' column is over 100%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the small number, remove the records that FT% is negative or over 100%\n",
    "data_cleaned.drop(data_cleaned[(data_cleaned['FT%']<0)|(data_cleaned['FT%']>100)].index,inplace=True)\n",
    "\n",
    "# Method 2\n",
    "# data_cleaned=data_cleaned[(data_cleaned['FT%']>=0)&(data_cleaned['FT%']<=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1029 rows where 'BLK' column is negative.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows where BLK is negative\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['BLK']<0])} rows where 'BLK' column is negative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the significant number of rows, the column of 'BLK' is removed from the dataset\n",
    "data_cleaned.drop(['BLK'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the whether there are duplicate rows\n",
    "sum(data_cleaned.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7939, 16)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display number of rows and columns after data cleansing\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the columns 'TOTAL_MIN','TOTAL_PTS' and 'FG/FT'\n",
    "data_cleaned['TOTAL_MIN']=data_cleaned['MIN'] * data_cleaned['GP']\n",
    "data_cleaned['TOTAL_PTS']=data_cleaned['PTS'] * data_cleaned['GP']\n",
    "data_cleaned['FG/FT']=data_cleaned['FG%']/data_cleaned['FT%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7939, 19)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display number of rows and columns after data cleansing\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "      <th>TOTAL_MIN</th>\n",
       "      <th>TOTAL_PTS</th>\n",
       "      <th>FG/FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.30</td>\n",
       "      <td>7.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.40</td>\n",
       "      <td>45.70</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>72.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1944.00</td>\n",
       "      <td>624.00</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.80</td>\n",
       "      <td>10.50</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.90</td>\n",
       "      <td>55.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>67.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1635.00</td>\n",
       "      <td>787.50</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.50</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>75.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1623.50</td>\n",
       "      <td>382.50</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.10</td>\n",
       "      <td>8.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.70</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.50</td>\n",
       "      <td>66.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1203.30</td>\n",
       "      <td>516.60</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.80</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>50.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1121.40</td>\n",
       "      <td>233.10</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  FTM  FTA   FT%  OREB  DREB  REB  AST  STL  \\\n",
       "0  80 24.30  7.80 3.00 6.40 45.70 2.00 2.90 72.10  2.20  2.00 3.80 3.20 1.10   \n",
       "1  75 21.80 10.50 4.20 7.90 55.10 2.40 3.60 67.80  3.60  3.70 6.60 0.70 0.50   \n",
       "2  85 19.10  4.50 1.90 4.50 42.80 0.40 0.60 75.70  0.60  1.80 2.40 0.80 0.40   \n",
       "3  63 19.10  8.20 3.50 6.70 52.50 0.90 1.50 66.90  0.80  2.00 3.00 1.80 0.40   \n",
       "4  63 17.80  3.70 1.70 3.40 50.80 0.20 0.50 54.00  2.40  2.70 4.90 0.40 0.40   \n",
       "\n",
       "   TOV  TARGET_5Yrs  TOTAL_MIN  TOTAL_PTS  FG/FT  \n",
       "0 1.60            1    1944.00     624.00   0.63  \n",
       "1 1.40            1    1635.00     787.50   0.81  \n",
       "2 0.60            1    1623.50     382.50   0.57  \n",
       "3 1.90            1    1203.30     516.60   0.78  \n",
       "4 0.70            1    1121.40     233.10   0.94  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column 'TARGET_5Yrs' and save it into variable called target\n",
    "target=data_cleaned.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler from sklearn.preprocessing and instantiate the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and apply the scaling on data_cleaned\n",
    "data_cleaned=scaler.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler_dropped_fe.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dump from joblib and save the scaler into the folder models and call the file scaler.joblib\n",
    "from joblib import dump\n",
    "\n",
    "dump(scaler, '../models/scaler_dropped_fe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function scaler_split_train_test from data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the scaler data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val=split_train_test(df=data_cleaned,target=target,test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function save_sets from sets and save the sets into the folder data/processed\n",
    "from src.data.sets import save_sets\n",
    "save_sets(X_train, y_train, X_val, y_val, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function load_sets from sets and load the sets from data/processed\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models Comparison with Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lazypredict package\n",
    "import lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LazyClassifier from lazypredict.Supervised\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit the Lazyclassifier model based on train set and predict the validation set\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "QuadraticDiscriminantAnalysis      0.61               0.63     0.69      0.66   \n",
       "BernoulliNB                        0.63               0.63     0.68      0.68   \n",
       "GaussianNB                         0.54               0.61     0.69      0.60   \n",
       "LabelPropagation                   0.76               0.54      NaN      0.76   \n",
       "KNeighborsClassifier               0.82               0.54     0.59      0.79   \n",
       "LabelSpreading                     0.76               0.54      NaN      0.76   \n",
       "ExtraTreeClassifier                0.74               0.54     0.54      0.75   \n",
       "DecisionTreeClassifier             0.73               0.54     0.54      0.74   \n",
       "XGBClassifier                      0.83               0.53     0.66      0.79   \n",
       "LinearDiscriminantAnalysis         0.84               0.53     0.73      0.79   \n",
       "BaggingClassifier                  0.80               0.53     0.62      0.78   \n",
       "RandomForestClassifier             0.84               0.52     0.67      0.79   \n",
       "AdaBoostClassifier                 0.84               0.51     0.70      0.78   \n",
       "CalibratedClassifierCV             0.84               0.51     0.73      0.78   \n",
       "LGBMClassifier                     0.83               0.51     0.69      0.78   \n",
       "ExtraTreesClassifier               0.84               0.51     0.67      0.78   \n",
       "LogisticRegression                 0.84               0.50     0.73      0.77   \n",
       "DummyClassifier                    0.84               0.50     0.50      0.77   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "QuadraticDiscriminantAnalysis        0.04  \n",
       "BernoulliNB                          0.02  \n",
       "GaussianNB                           0.02  \n",
       "LabelPropagation                     2.22  \n",
       "KNeighborsClassifier                 0.17  \n",
       "LabelSpreading                       3.40  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "DecisionTreeClassifier               0.10  \n",
       "XGBClassifier                        0.79  \n",
       "LinearDiscriminantAnalysis           0.05  \n",
       "BaggingClassifier                    0.56  \n",
       "RandomForestClassifier               1.40  \n",
       "AdaBoostClassifier                   0.41  \n",
       "CalibratedClassifierCV               1.74  \n",
       "LGBMClassifier                       0.27  \n",
       "ExtraTreesClassifier                 0.77  \n",
       "LogisticRegression                   0.08  \n",
       "DummyClassifier                      0.01  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the metrics of classifiers\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lazypredict_dropped_fe.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Import dump from joblib and save the fitted model into the folder models as a file called lazypredict_cleaned\n",
    "from joblib import dump \n",
    "\n",
    "dump(clf,  '../models/lazypredict_dropped_fe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5087c292a60e433539a3ea1db33a548e8b6d2b5fd0ec051734d3134be8f1ad1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
