{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of this week's line of experimentation is model testing and hyperparameter tuning. Random Forest (Random Search vs. Grid Search) and Support Vector Machine (C and Gamma manual tuning). In order to accurately compare our results to last week's insights, we will retain the same cleaned dataset and compare AUROC's accordingly. As per our group discussion, Amy will focus her attention this week on further cleaning, feature engineering and Logistic Regression. Yatin will explore KNN and XGBoost. At the end of the week we will combine our findings to narrow down: \n",
    "\n",
    "1. The best performing model (by AUROC) \n",
    "2. The cleaned dataset that best enhances these results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas, numpy packages and dump from joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved sets from last week (data/processed) using numpy\n",
    "X_train = np.load('../data/processed/X_train.npy')\n",
    "X_val   = np.load('../data/processed/X_val.npy'  )\n",
    "y_train = np.load('../data/processed/y_train.npy')\n",
    "y_val   = np.load('../data/processed/y_val.npy'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Initial Random Forest Model with Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomForestClassifier class called rf1 with a random state=8\n",
    "rf1 = RandomForestClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomForest model\n",
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability when target=1\n",
    "probs_train=rf1.predict_proba(X_train)[:,1]\n",
    "probs_val=rf1.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_auc_score and roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 1.0\n",
      "Val ROC AUC  Score: 0.6740837144920558\n"
     ]
    }
   ],
   "source": [
    "# Print the ROC AUC score for train and validation data\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the random forest model with default hyperparameters is clearly overfitting. Unlike last week, let us explore hyperparameter tuning with Grid Search to see if it yields a better result. Note: the AUROC scores last week for Random Forest with Random Search were 0.7812 and 0.7067 for the training and validation sets respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import GridSearchCV from sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': array([10, 30, 50, 70, 90]),\n",
       " 'max_depth': array([ 5, 10, 15, 20, 25]),\n",
       " 'min_samples_leaf': array([ 2,  6, 10, 14, 18])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a dictionary containing the grid search parameters\n",
    "hyperparams_grid2 = {\n",
    "    'n_estimators': np.arange(10, 100, 20),\n",
    "    'max_depth': np.arange(5, 30, 5),\n",
    "    'min_samples_leaf': np.arange(2, 20, 4)\n",
    "    }\n",
    "hyperparams_grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the RandomForestClassifier from sklearn.ensemble and instantiate the RandomForestClassifier class called rf with a random state=8\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf2 = RandomForestClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a GridSearchCV with the hyperparameter grid and the random forest model\n",
    "grid_search_rf2 = GridSearchCV(rf2, hyperparams_grid2, cv=2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 125 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=8),\n",
       "             param_grid={&#x27;max_depth&#x27;: array([ 5, 10, 15, 20, 25]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([ 2,  6, 10, 14, 18]),\n",
       "                         &#x27;n_estimators&#x27;: array([10, 30, 50, 70, 90])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=8),\n",
       "             param_grid={&#x27;max_depth&#x27;: array([ 5, 10, 15, 20, 25]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([ 2,  6, 10, 14, 18]),\n",
       "                         &#x27;n_estimators&#x27;: array([10, 30, 50, 70, 90])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=8),\n",
       "             param_grid={'max_depth': array([ 5, 10, 15, 20, 25]),\n",
       "                         'min_samples_leaf': array([ 2,  6, 10, 14, 18]),\n",
       "                         'n_estimators': array([10, 30, 50, 70, 90])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the GridSearchCV on the training set\n",
    "grid_search_rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'min_samples_leaf': 10, 'n_estimators': 50}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best set of hyperparameters\n",
    "grid_search_rf2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=grid_search_rf2.predict_proba(X_train)[:,1]\n",
    "probs_val=grid_search_rf2.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid_Search_Train ROC AUC Score: 0.9292779367147442\n",
      "Grid_Search_Val ROC AUC  Score: 0.6989618440057775\n"
     ]
    }
   ],
   "source": [
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Grid_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Grid_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search performs well but is still prone to overfitting and underperforms in comparison to the random search model from last week. Let us see if we can improve this score by amending the hyperparameter dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 480 candidates, totalling 960 fits\n",
      "Grid_Search_Train ROC AUC Score: 0.7884951059885361\n",
      "Grid_Search_Val ROC AUC  Score: 0.708266129032258\n"
     ]
    }
   ],
   "source": [
    "# Let's create a new dictionary containing amended grid search parameters with a greater range and number of fits \n",
    "\n",
    "hyperparams_grid3 = {\n",
    "    'n_estimators': np.arange(5, 200, 40),\n",
    "    'max_depth': np.arange(1, 40, 5),\n",
    "    'min_samples_leaf': np.arange(1, 60, 5)\n",
    "    }\n",
    "hyperparams_grid3\n",
    "\n",
    "#Import the RandomForestClassifier from sklearn.ensemble and instantiate the RandomForestClassifier class called rf with a random state=8\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf3 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "#Instantiate a GridSearchCV with the hyperparameter grid and the random forest model\n",
    "grid_search_rf3 = GridSearchCV(rf3, hyperparams_grid3, cv=2, verbose=1)\n",
    "\n",
    "#Fit the GridSearchCV on the training set\n",
    "grid_search_rf3.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=grid_search_rf3.predict_proba(X_train)[:,1]\n",
    "probs_val=grid_search_rf3.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Grid_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Grid_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUROC score has improved and overfitting has been reduced. This process however took approximately 5 minutes to execute. Further increasing the hyperparameter range and number of fits would not be the most effective use of time and resources currently. Let us use a new dictionary that compromises between rf2 and rf3 in terms of the number of fits and models tested to see if the result can be improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 200 candidates, totalling 400 fits\n",
      "Grid_Search_Train ROC AUC Score: 0.999740161223188\n",
      "Grid_Search_Val ROC AUC  Score: 0.6932926095329803\n"
     ]
    }
   ],
   "source": [
    "# Let's create a new dictionary with grid parameters compromising the pros and cons of rf2 and rf3 explored above\n",
    "hyperparams_grid4 = {\n",
    "    'n_estimators': np.arange(10, 200, 20),\n",
    "    'max_depth': np.arange(5, 40, 10),\n",
    "    'min_samples_leaf': np.arange(2, 50, 10)\n",
    "    }\n",
    "hyperparams_grid4\n",
    "\n",
    "#Import the RandomForestClassifier from sklearn.ensemble and instantiate the RandomForestClassifier class called rf with a random state=8\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf4 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "#Instantiate a GridSearchCV with the hyperparameter grid and the random forest model\n",
    "grid_search_rf4 = GridSearchCV(rf4, hyperparams_grid4, cv=2, verbose=1)\n",
    "\n",
    "#Fit the GridSearchCV on the training set\n",
    "grid_search_rf4.fit(X_train, y_train)\n",
    "\n",
    "#Display the best set of hyperparameters\n",
    "grid_search_rf4.best_params_\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=grid_search_rf4.predict_proba(X_train)[:,1]\n",
    "probs_val=grid_search_rf4.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Grid_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Grid_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compromise has been made with 400 models tested (compared to 250 in rf2 and 960 in rf3). The AUROC score has worsened so it seems random search may prove to be a more effective compromise between time/resources and performance. As of right now, Grid Search outperforms the Random Search model tested last week. Let us see if the hyperparameter range used for the random search model can be tuned to provide better results that require less computational power to execute.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import randint from scipy.stats\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters. Let us use the parameters for random search last week as a starting point, ensuring our parameters fall within the same range.\n",
    "# {'max_depth': 10, 'min_samples_leaf': 46, 'n_estimators': 186}\n",
    "# However, let us reduce the n_estimators to see if there is a trade off between performance and computation. \n",
    "\n",
    "hyperparams_dist5 = {\n",
    "'n_estimators': randint(35, 50),\n",
    "'max_depth': randint(10, 30),\n",
    "'min_samples_leaf': randint(31,50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomizedSearchCV and KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "rf5 = RandomForestClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf5 = RandomizedSearchCV(rf5, hyperparams_dist5, random_state=8, cv=kf_cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=RandomForestClassifier(random_state=8),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB17D60&gt;,\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB0C8E0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB17EE0&gt;},\n",
       "                   random_state=8, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=RandomForestClassifier(random_state=8),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB17D60&gt;,\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB0C8E0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB17EE0&gt;},\n",
       "                   random_state=8, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=RandomForestClassifier(random_state=8),\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB17D60>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB0C8E0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002D9AFB17EE0>},\n",
       "                   random_state=8, verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 22, 'min_samples_leaf': 44, 'n_estimators': 44}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best set of hyperparameters\n",
    "random_search_rf5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf5.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf5.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Search_Train ROC AUC Score: 0.7844567856623883\n",
      "Random_Search_Val ROC AUC  Score: 0.7087084737602312\n"
     ]
    }
   ],
   "source": [
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to last week's results (below), the AUROC score has improved and now outperforms the Grid Search tuned model.\n",
    "\n",
    "Original_Random_Search_Train ROC AUC Score: 0.7812034352902928\n",
    "Original_Random_Search_Val ROC AUC  Score: 0.706701372171401\n",
    "\n",
    "Increasing max_depth tends to improve the models performance but increases risk of overfitting. Let us see if this can help us further improve the models performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random_Search_Train ROC AUC Score: 0.8029553010453014\n",
      "Random_Search_Val ROC AUC  Score: 0.7097496389022628\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters value range. Keep n_estimators and min_samples_leaf the same but increase max_depth. \n",
    "hyperparams_dist6 = {\n",
    "'n_estimators': randint(35, 50),\n",
    "'max_depth': randint(30, 40),\n",
    "'min_samples_leaf': randint(31,50)\n",
    "}\n",
    "\n",
    "rf6 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)\n",
    "\n",
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf6 = RandomizedSearchCV(rf6, hyperparams_dist6, random_state=8, cv=kf_cv, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf6.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf6.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf6.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has improved even further, resulting in our best result to date. There is also very little overfitting. Let us see if increasing the max_depth further will improve our result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random_Search_Train ROC AUC Score: 0.7844567856623883\n",
      "Random_Search_Val ROC AUC  Score: 0.7087084737602312\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters value range. Keep n_estimators and min_samples_leaf the same but increase max_depth further. \n",
    "hyperparams_dist7 = {\n",
    "'n_estimators': randint(35, 50),\n",
    "'max_depth': randint(50, 70),\n",
    "'min_samples_leaf': randint(31,50)\n",
    "}\n",
    "\n",
    "rf7 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)\n",
    "\n",
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf7 = RandomizedSearchCV(rf7, hyperparams_dist7, random_state=8, cv=kf_cv, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf7.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf7.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf7.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC has slightly reduced. We will retain the max_depth in hyperparams_dist6. Generally speaking, a higher n_estimator means more trees and therefore better performance. Let us try increasing it slightly to see if performance can be improved without too much of an increase in computational power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random_Search_Train ROC AUC Score: 0.7922118384446687\n",
      "Random_Search_Val ROC AUC  Score: 0.7058497833413577\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters value range. Keep max_depth and min_samples_leaf the same as rf6 but increase n_estimators. \n",
    "hyperparams_dist8 = {\n",
    "'n_estimators': randint(55, 95),\n",
    "'max_depth': randint(30, 40),\n",
    "'min_samples_leaf': randint(31,50)\n",
    "}\n",
    "\n",
    "rf8 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)\n",
    "\n",
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf8 = RandomizedSearchCV(rf8, hyperparams_dist8, random_state=8, cv=kf_cv, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf8.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf8.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf8.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our AUROC score has worsened yet again and we will therefore retain n_estimators between 35 and 50. We want to avoid decreasing min_samples_leaf to avoid very specific rules that apply to just a few observations. Higher values reduce the risk of overfitting. Let us see if our AUROC improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random_Search_Train ROC AUC Score: 0.751389970328769\n",
      "Random_Search_Val ROC AUC  Score: 0.7046732065479056\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters value range. Keep n_estimators and max_depth the same as rf6 but increase min_samples_leaf.  \n",
    "hyperparams_dist9 = {\n",
    "'n_estimators': randint(35, 50),\n",
    "'max_depth': randint(30, 40),\n",
    "'min_samples_leaf': randint(50,100)\n",
    "}\n",
    "\n",
    "rf9 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)\n",
    "\n",
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf9 = RandomizedSearchCV(rf9, hyperparams_dist9, random_state=8, cv=kf_cv, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf9.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf9.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf9.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the min_samples_leaf has also worsened the AUROC score. We shall proceed with the range of values dictated in hyperparams_dist6 (rf6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 39, 'min_samples_leaf': 36, 'n_estimators': 48}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best set of hyperparameters\n",
    "random_search_rf6.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tuned our Random Forest via Random Search, let us look at a different type of model - Support Vector Machine (SVM). We will explore the AUROC with default hyperparameters then tune with C, Gamma and kernel type hyperparameters. We will compare its performance to our best Random Forest score (0.7097) to see which model is better suited at predicting if a rookie player will last at least 5 years in the NBA league based on their current stats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Initial SVM with Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SVC from sklearn.svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a SVC() model with default hyperparameters except probability = True for AUROC\n",
    "svc_0=SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model on the train set \n",
    "\n",
    "svc_0.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability when target=1\n",
    "probs_train=svc_0.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_0.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_auc_score, roc_curve, matplotlib.pyplot\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.8131324664065582\n",
      "Val ROC AUC  Score: 0.6251354116514203\n"
     ]
    }
   ],
   "source": [
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': True,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_0.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with Default Hyperparameters is overfitting and performs worse (AUROC) in comparison to Random Forest with default hyperparameters, grid search or random forest. Let us see if hyperparameter tuning will increase its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - Gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.6020638622843928\n",
      "Val ROC AUC  Score: 0.5456337265286471\n"
     ]
    }
   ],
   "source": [
    "#Gamma 1\n",
    "\n",
    "svc_1 = SVC(C=1.0, kernel='rbf',gamma=0.005, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_1.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_1.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_1.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC is worse than with default hyperparameters. Let us increase gamma to see if results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.8345361798668403\n",
      "Val ROC AUC  Score: 0.6154399374097255\n"
     ]
    }
   ],
   "source": [
    "#Gamma 2\n",
    "\n",
    "svc_2 = SVC(C=1.0, kernel='rbf',gamma=0.1, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_2.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_2.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_2.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing gamma has improved the AUROC of both training and validation sets but increased overfitting. Larger gamma results tend to increase overfitting so we will attempt to optimise gamma within the range of 0.005 and 0.1. As 0.1 yielded much better results, we start by testing values closer to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.8289506137437649\n",
      "Val ROC AUC  Score: 0.6194240491092922\n"
     ]
    }
   ],
   "source": [
    "#Gamma 3\n",
    "svc_3 = SVC(C=1.0, kernel='rbf',gamma=0.09, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_3.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_3.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_3.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC has improved and overfitting has reduced. Let us lower the gamma to see the effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.803231852539647\n",
      "Val ROC AUC  Score: 0.6280181752527684\n"
     ]
    }
   ],
   "source": [
    "#Gamma 4\n",
    "svc_4 = SVC(C=1.0, kernel='rbf',gamma=0.05, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_4.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_4.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_4.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC has once again improved and overfitting reduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.7425463918650231\n",
      "Val ROC AUC  Score: 0.6319210399614829\n"
     ]
    }
   ],
   "source": [
    "#Gamma 5\n",
    "svc_5 = SVC(C=1.0, kernel='rbf',gamma=0.02, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_5.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_5.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_5.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC has further improved and overfitting reduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.6760186929106764\n",
      "Val ROC AUC  Score: 0.6003761434761675\n"
     ]
    }
   ],
   "source": [
    "#Gamma 6\n",
    "svc_6 = SVC(C=1.0, kernel='rbf',gamma=0.01, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_6.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_6.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_6.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whilst overfitting has reduced, the AUROC validation score has worsened. It seems the optimal gamma value is between 0.01 and 0.02. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.726139429100606\n",
      "Val ROC AUC  Score: 0.6303863745787193\n"
     ]
    }
   ],
   "source": [
    "#Gamma 7\n",
    "svc_7 = SVC(C=1.0, kernel='rbf',gamma=0.015, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_7.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_7.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_7.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation AUROC is slightly worse compared to a gamma of 0.02. Let us test closer to 0.02 as one final check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.7486773203497215\n",
      "Val ROC AUC  Score: 0.6245456186807896\n"
     ]
    }
   ],
   "source": [
    "#Gamma 8\n",
    "svc_8 = SVC(C=1.0, kernel='rbf',gamma=0.019, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_8.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_8.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_8.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation AUROC has worsened once again. It seems Gamma #7 with a value of 0.02 has performed best. We will proceed with this. The performance is still quite low compared to Random Forest bur we will do a few quick checks with tuning C and kernel type to see if there is any significant difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.7944805458690208\n",
      "Val ROC AUC  Score: 0.6434099662975445\n"
     ]
    }
   ],
   "source": [
    "#C1 - increasing C to a large value to test effect\n",
    "svc_9 = SVC(C=1000.0, kernel='rbf',gamma=0.02, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_9.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_9.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_9.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing C to 1000 has improved validation AUROC but increased overfitting and requires a higher degree of computational power. Let us try reducing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.7801427934586072\n",
      "Val ROC AUC  Score: 0.6498104236880116\n"
     ]
    }
   ],
   "source": [
    "#C2\n",
    "svc_10 = SVC(C=20.0, kernel='rbf',gamma=0.02, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_10.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_10.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_10.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = 20 seems to yield a better AUROC with less overfitting and reduced computational strain. The tuned SVM model still however performs poorly compared to Random Forest with Hyperparameter tuning (Random Search and Grid Search). Let us do one final check with kernel type. The default is rbf. The data is not linear in nature so not worthwhile using this kernel type. Precomputed matrix must be a square matrix so cannot be applied. We will therefore test poly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.7248662718712298\n",
      "Val ROC AUC  Score: 0.6589461964371689\n"
     ]
    }
   ],
   "source": [
    "#Poly Kernel Type\n",
    "svc_11 = SVC(C=20.0, kernel='poly',gamma=0.02, probability=True)\n",
    "\n",
    "#Train the model on the train set \n",
    "svc_11.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=svc_11.predict_proba(X_train)[:,1]\n",
    "probs_val=svc_11.predict_proba(X_val)[:,1]\n",
    "\n",
    "#Print the AUROC score of the training set \n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poly has improved the score and reduced overfitting compared to rbf. We have now fully tuned our SVM model but it is clear that it does not perform as well as Random Forest. It will be interesting to see what models performed best from Amy and Yatin's experimentation (Logistic Regression, KNN and XGBoost). Random Forest will be compared to them in the coming weeks and with further data cleaning and feature engineering, an AUROC score better than our current high of 0.7097 will be hopefully be achieved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clean the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file of test data and save into data_test\n",
    "data_test=pd.read_csv('../data/raw/2022_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data_test and save it into a variable data_test_cleaned\n",
    "data_test_cleaned=data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns of id, 3P Made, 3PA, 3P% and BLK\n",
    "data_test_cleaned.drop(['Id','3P Made','3PA','3P%','BLK'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and apply the scaling on data_test_cleaned\n",
    "data_test_cleaned=scaler.fit_transform(data_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable X_test\n",
    "X_test=data_test_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities for test datasets\n",
    "probs_test=random_search_rf6.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the probs_test column into data_test\n",
    "data_test['TARGET_5Yrs']=probs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the csv file 'rf_submission_091122.csv' for Kaggle submission\n",
    "output=data_test[['Id','TARGET_5Yrs']]\n",
    "output.to_csv('../rf6_submission_091122.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93e5285b5ee05b08152baf054ff49b5b3546c84ca307065b8c0361b70cc13ad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
