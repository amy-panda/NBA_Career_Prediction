{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After discussion at the end of week 2, Amy shared the data cleaning procedures she had tested and the improved AUROC scores she received. This newly cleaned data was pushed to the master branch. Let us begin by loading it and testing our best model thus far to see if there is an improvement in the AUROC score. Source: yang_yang-14169837-week2_dataprocessing_lazypredict.ipynb [Github Link: (master branch - notebooks) - https://github.com/amy-panda/NBA_Career_Prediction.git]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned dataset using load_sets function defined in src.data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/week2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us re-run the Random Forest with Random Search model from last week and see if there is an improvement in the AUROC score with this newly cleaned data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random_Search_Train ROC AUC Score: 0.7995328883411028\n",
      "Random_Search_Val ROC AUC  Score: 0.7097045016851229\n"
     ]
    }
   ],
   "source": [
    "# Import the RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import randint from scipy.stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameters value range. Keep n_estimators and min_samples_leaf the same but increase max_depth. \n",
    "hyperparams_dist6 = {\n",
    "'n_estimators': randint(35, 50),\n",
    "'max_depth': randint(30, 40),\n",
    "'min_samples_leaf': randint(31,50)\n",
    "}\n",
    "# Import RandomizedSearchCV and KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "rf6 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)\n",
    "\n",
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf6 = RandomizedSearchCV(rf6, hyperparams_dist6, random_state=8, cv=kf_cv, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf6.fit(X_train, y_train)\n",
    "\n",
    "# Import the roc_auc_score and roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf6.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf6.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is very little difference in the AUROC score (0.7097496 vs.0.7097045). The validation AUROC has reduced marginally by approximately 0.00005 (5dp) but overfitting has reduced slightly as well (0.093206 vs. 0.089828 difference between training and validation scores). This cleaned dataset improves upon the last by increasing dimensionality through feature engineering which can be very useful in training a model. We will proceed with this newly cleaned dataset and see if we can improve upon it further as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering & Re-running Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned dataset using load_sets function defined in src.data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/week3') #data cleaning and feature engineering performed under - vimalasri_chanthru-NA-week3_dataprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Random_Search_Train ROC AUC Score: 0.7999084846772528\n",
      "Random_Search_Val ROC AUC  Score: 0.7099572701011073\n"
     ]
    }
   ],
   "source": [
    "# Re-Run Random Forest with Random Search (best model from prior experiment) with data cleaning/feature engineering from this week (week3)\n",
    "\n",
    "# Import the RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import randint from scipy.stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameters value range. Keep n_estimators and min_samples_leaf the same but increase max_depth. \n",
    "hyperparams_dist6 = {\n",
    "'n_estimators': randint(35, 50),\n",
    "'max_depth': randint(30, 40),\n",
    "'min_samples_leaf': randint(31,50)\n",
    "}\n",
    "# Import RandomizedSearchCV and KFold from sklearn.model_selection\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "rf6 = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Instantiate a KFold with 5 splits\n",
    "kf_cv = KFold(n_splits=5)\n",
    "\n",
    "# Instantiate a RandomizedSearchCV with the hyperparameter values and the random forest model\n",
    "random_search_rf6 = RandomizedSearchCV(rf6, hyperparams_dist6, random_state=8, cv=kf_cv, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training set\n",
    "random_search_rf6.fit(X_train, y_train)\n",
    "\n",
    "# Import the roc_auc_score and roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Calculate the probabilities for train and validation datasets\n",
    "probs_train=random_search_rf6.predict_proba(X_train)[:,1]\n",
    "probs_val=random_search_rf6.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Calculate the roc_auc_score for train and validation dataset\n",
    "print(f'Random_Search_Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "print(f'Random_Search_Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC score and overfitting has improved slightly. We will proceed with this newly cleaned data as our base. Further discussions with our team highlighted the potential for XGBoost model prediction. Between Logistic Regression, KNN, SVM, Random Forest and XGBoost models tested by our team over the past three weeks, XGBoost performed the best. The focus now shifted to training a XGBoost model to see if it could outperform our Random Forest with Random Search score above (0.7100 (4dp)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost (Default Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Training: 0.9996618753357936\n",
      "ROC AUC Score Validation: 0.6596774193548387\n"
     ]
    }
   ],
   "source": [
    "#Let us run a XG Boost model with Default Hyperparameters using the week 3 processed data. \n",
    "\n",
    "# Train Xgboost model\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Instantiate the RandomForest class into a variable called rf with random_state=8\n",
    "\n",
    "xgboost1 = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model with the prepared data\n",
    "\n",
    "xgboost1.fit(X_train, y_train)\n",
    "\n",
    "# Import `dump` from `joblib` and save the fitted model into the folder `models` as a file called `xgboost_default`\n",
    "\n",
    "from joblib import dump \n",
    "\n",
    "dump(xgboost1,  '../models/xgboost_default.joblib')\n",
    "\n",
    "# Calculate and save the probability when target=1 for training and validation sets into 2 variables called `y_train_preds` and `y_val_preds`\n",
    "\n",
    "y_train_preds = xgboost1.predict_proba(X_train)[:,1]\n",
    "y_val_preds = xgboost1.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Import `print_class_perf` from `src/models/performance` and display the AUROC score of this baseline model on the training and validation sets\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "\n",
    "print_class_perf(y_probs=y_train_preds, y_actuals=y_train, set_name='Training')\n",
    "print_class_perf(y_probs=y_val_preds, y_actuals=y_val, set_name='Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor AUROC score and overfitting. Let us try to combat this with hyperparameter tuning via Hyperopt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost (Hyperparameter Tuning via Hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.59s/trial, best loss: 0.32807957679871413]\n",
      "Best:  {'colsample_bytree': 0.4, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 7.0, 'subsample': 0.55}\n",
      "ROC AUC Score Training: 0.8373546477363767\n",
      "ROC AUC Score Validation: 0.7138149975926819\n"
     ]
    }
   ],
   "source": [
    "#XG Boost with Hyperopt Hyperparameter Tuning \n",
    "\n",
    "#Import Trials, STATUS_OK, tpe, hp, fmin from hyperopt package\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin\n",
    "\n",
    "#Define the search space for xgboost hyperparameters\n",
    "\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 20, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.05),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "}\n",
    "\n",
    "#Define a function called `objective` with the following logics:\n",
    "    #-input parameters: hyperparameter seacrh space (`space`)\n",
    "    #-logics: train a xgboost model with the search space and calculate the average accuracy score for cross validation with 10 folds\n",
    "    #-output parameters: dictionary with the loss score and STATUS_OK\n",
    "\n",
    "def objective(space):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree'])\n",
    "    \n",
    "    roc_auc = cross_val_score(xgboost, X_train, y_train, cv=10, scoring=\"roc_auc\").mean()\n",
    "\n",
    "    return{'loss': 1-roc_auc, 'status': STATUS_OK }\n",
    "\n",
    "# Launch Hyperopt search and save the result in a variable called `best`\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,   \n",
    "    space=space,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")\n",
    "\n",
    "# Print the best set of hyperparameters\n",
    "\n",
    "print(\"Best: \", best)\n",
    "\n",
    "# Instantiate a XGBClassifier with best set of hyperparameters\n",
    "\n",
    "xgboost2 = xgb.XGBClassifier(\n",
    "    max_depth = best['max_depth'],\n",
    "    learning_rate = best['learning_rate'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    subsample = best['subsample'],\n",
    "    colsample_bytree = best['colsample_bytree'])\n",
    "\n",
    "# Fit the model with the prepared data\n",
    "\n",
    "xgboost2.fit(X_train, y_train)\n",
    "\n",
    "# Save the fitted model into the folder models as a file called `xgboost_best`\n",
    "\n",
    "dump(xgboost2,  '../models/xgboost_best.joblib')\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "\n",
    "probs_train=xgboost2.predict_proba(X_train)[:,1]\n",
    "probs_val=xgboost2.predict_proba(X_val)[:,1]\n",
    "\n",
    "\n",
    "#Display the AUROC score of this tuned model on the training and validation sets\n",
    "\n",
    "print_class_perf(y_probs=probs_train, y_actuals=y_train, set_name='Training')\n",
    "print_class_perf(y_probs=probs_val, y_actuals=y_val, set_name='Validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see this run of our XGBoost model with Hyperopt hyperparameter tuning has yielded better results than our best random forest with random search. To give us more control, let us use the best parameters identified by the package as a base and attempt to generate better results. Best Parameters - {'colsample_bytree': 0.4, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 7.0, 'subsample': 0.55}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with Manual Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Training: 0.7606793385423062\n",
      "ROC AUC Score Validation: 0.7188493018777082\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the XGBClassifier class into a variable called xgb_manual where can optimise the hyperparameters. \n",
    "# Add n_estimators, eta, min_child_weight, scale_pos_weight (to handle imbalanced data), and gamma. \n",
    "\n",
    "xgb_manual = xgb.XGBClassifier(\n",
    "    n_estimators =150,\n",
    "    eta=0.02, \n",
    "    max_depth=3, \n",
    "    learning_rate=0.05,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.75,\n",
    "    scale_pos_weight=0.80,\n",
    "    gamma=5\n",
    "    ) \n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_manual.fit(X_train, y_train)\n",
    "\n",
    "# Import dump from joblib and save the model\n",
    "from joblib import dump \n",
    "\n",
    "dump(xgb_manual,  '../models/xgb_manual.joblib')\n",
    "\n",
    "# Calculate the probability when target=1\n",
    "probs_train=xgb_manual.predict_proba(X_train)[:,1]\n",
    "probs_val=xgb_manual.predict_proba(X_val)[:,1]\n",
    "\n",
    "\n",
    "# Import the function print_class_perf from models.performance and display the ROC-AUC score\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_actuals=y_train, y_probs=probs_train,set_name='Training')\n",
    "print_class_perf(y_actuals=y_val, y_probs=probs_val,set_name='Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our best AUROC score yet with relatively low overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load, clean and predict probabilities for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file of test data and save into data_test\n",
    "data_test=pd.read_csv('../data/raw/2022_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data_test and save it into a variable data_test_cleaned\n",
    "data_test_cleaned=data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns of id, 3P Made, 3PA, 3P% and BLK\n",
    "data_test_cleaned.drop(['Id','3P Made','3PA','3P%','BLK'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the columns 'TOTAL_MIN','TOTAL_PTS' and 'FG/FT'\n",
    "data_test_cleaned['TOTAL_MIN']=data_test_cleaned['MIN'] * data_test_cleaned['GP']\n",
    "data_test_cleaned['TOTAL_PTS']=data_test_cleaned['PTS'] * data_test_cleaned['GP']\n",
    "data_test_cleaned['FG/FT']=data_test_cleaned['FG%']/data_test_cleaned['FT%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and apply the scaling on data_test_cleaned\n",
    "data_test_cleaned=scaler.fit_transform(data_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable X_test\n",
    "X_test=data_test_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities for test datasets\n",
    "probs_test=xgb_manual.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the probs_test column into data_test\n",
    "data_test['TARGET_5Yrs']=probs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the csv file 'rf_submission_091122.csv' for Kaggle submission\n",
    "output=data_test[['Id','TARGET_5Yrs']]\n",
    "output.to_csv('../XGBoost_Manual_chanthru_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93e5285b5ee05b08152baf054ff49b5b3546c84ca307065b8c0361b70cc13ad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
