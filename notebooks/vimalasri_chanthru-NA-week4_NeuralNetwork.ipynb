{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**[5.1]** Import `torch`, `torch.nn` as `nn` and `torch.nn.functional` as `F`# Solution:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**[5.2]** Create in `src/models/pytorch.py` a class called `PytorchBinary` that inherits from `nn.Module` with:\n",
    "#- `num_features` as input parameter\n",
    "#- attributes:\n",
    "#    - `layer_1`: fully-connected layer with 256 neurons\n",
    "#    - `layer_out`: fully-connected layer with 1 neurons\n",
    "#    - `sigmoid`: sigmoid function\n",
    "#- methods:\n",
    "#    - `forward()` with `inputs` as input parameter, perform ReLU and DropOut on the fully-connected layer followed by the output layer with sigmoid\n",
    "\n",
    "# Solution:\n",
    "\n",
    "class PytorchBinary(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchBinary, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 256)\n",
    "        self.layer_out = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)))\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**[5.3]** Instantiate `PytorchBinary` with the correct number of input feature and save it into a variable called `model`\n",
    "\n",
    "# Solution:\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "\n",
    "from src.models.pytorch import PytorchBinary\n",
    "\n",
    "model = PytorchBinary(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchBinary(\n",
       "  (layer_1): Linear(in_features=18, out_features=256, bias=True)\n",
       "  (layer_out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#**[5.4]** Import `get_device()` from `src.models.pytorch` and set `model` to use the device available\n",
    "\n",
    "# Solution:\n",
    "import sys\n",
    "sys.path.insert(1,'..')\n",
    "\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchBinary(\n",
      "  (layer_1): Linear(in_features=18, out_features=256, bias=True)\n",
      "  (layer_out): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#**[5.5]** Print the architecture of `model`\n",
    "\n",
    "# Solution:\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**[6.1]** Instantiate a `nn.BCELoss()` and save it into a variable called `criterion` \n",
    "\n",
    "# Solution:\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**[6.2]** Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.001 as learning rate and save it into a variable called `optimizer`\n",
    "\n",
    "# Solution:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6.3] Instantiate a torch.optim.lr_scheduler.StepLR() scheduler that will decrease the learning rate by a coefficient of 0.9 for each epoch\n",
    "\n",
    "# Solution:\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6.5] Create 2 variables called N_EPOCHS and BATCH_SIZE that will take respectively 10 and 32 as values\n",
    "\n",
    "# Solution:\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset and DataLoader from torch.utils.data\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#**[6.3]** Import this class from `src/models/pytorch` and convert all sets to PytorchDataset\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "\n",
    "#**[6.4]** Import DataLoader from `torch.utils.data`\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\tLoss: 0.0137\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0129\t|\tAcc: 15.6%\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0129\t|\tAcc: 15.6%\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0128\t|\tAcc: 15.6%\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0128\t|\tAcc: 15.6%\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0129\t|\tAcc: 15.6%\n",
      "Epoch: 5\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0129\t|\tAcc: 15.6%\n",
      "Epoch: 6\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0128\t|\tAcc: 15.6%\n",
      "Epoch: 7\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0128\t|\tAcc: 15.6%\n",
      "Epoch: 8\n",
      "\t(train)\tLoss: 0.0135\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0129\t|\tAcc: 15.6%\n",
      "Epoch: 9\n",
      "\t(train)\tLoss: 0.0136\t|\tAcc: 17.0%\n",
      "\t(valid)\tLoss: 0.0129\t|\tAcc: 15.6%\n"
     ]
    }
   ],
   "source": [
    "#[6.6] Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "\n",
    "from src.models.pytorch import train_binary, test_binary\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_binary(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device, scheduler=scheduler)\n",
    "    valid_loss, valid_acc = test_binary(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "    probs_train=rf1.predict_proba(X_train)[:,1]\n",
    "    probs_val=rf1.predict_proba(X_val)[:,1]\n",
    "\n",
    "    print(f'Train ROC AUC Score: {roc_auc_score(y_train, probs_train)}')\n",
    "    print(f'Val ROC AUC  Score: {roc_auc_score(y_val, probs_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6.7] Save the model into the models folder\n",
    "\n",
    "#Solution\n",
    "torch.save(model, \"../models/neural_network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6.8] Assess the model performance on the testing set and print its scores\n",
    "\n",
    "test_loss, test_acc = test_binary(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93e5285b5ee05b08152baf054ff49b5b3546c84ca307065b8c0361b70cc13ad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
