{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file and save into data\n",
    "data=pd.read_csv('../data/raw/2022_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>80</td>\n",
       "      <td>24.30</td>\n",
       "      <td>7.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.40</td>\n",
       "      <td>45.70</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>22.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>72.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>75</td>\n",
       "      <td>21.80</td>\n",
       "      <td>10.50</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.90</td>\n",
       "      <td>55.10</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>67.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>85</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.50</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.20</td>\n",
       "      <td>34.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>75.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>63</td>\n",
       "      <td>19.10</td>\n",
       "      <td>8.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.70</td>\n",
       "      <td>52.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>23.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.50</td>\n",
       "      <td>66.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>63</td>\n",
       "      <td>17.80</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>50.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  GP   MIN   PTS  FGM  FGA   FG%  3P Made   3PA   3P%  FTM  FTA   FT%  \\\n",
       "0  3799  80 24.30  7.80 3.00 6.40 45.70     0.10  0.30 22.60 2.00 2.90 72.10   \n",
       "1  3800  75 21.80 10.50 4.20 7.90 55.10    -0.30 -1.00 34.90 2.40 3.60 67.80   \n",
       "2  3801  85 19.10  4.50 1.90 4.50 42.80     0.40  1.20 34.30 0.40 0.60 75.70   \n",
       "3  3802  63 19.10  8.20 3.50 6.70 52.50     0.30  0.80 23.70 0.90 1.50 66.90   \n",
       "4  3803  63 17.80  3.70 1.70 3.40 50.80     0.50  1.40 13.70 0.20 0.50 54.00   \n",
       "\n",
       "   OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.20  2.00 3.80 3.20 1.10 0.20 1.60            1  \n",
       "1  3.60  3.70 6.60 0.70 0.50 0.60 1.40            1  \n",
       "2  0.60  1.80 2.40 0.80 0.40 0.20 0.60            1  \n",
       "3  0.80  2.00 3.00 1.80 0.40 0.10 1.90            1  \n",
       "4  2.40  2.70 4.90 0.40 0.40 0.60 0.70            1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of data and all the columns\n",
    "pd.set_option('max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id           8000 non-null   int64  \n",
      " 1   GP           8000 non-null   int64  \n",
      " 2   MIN          8000 non-null   float64\n",
      " 3   PTS          8000 non-null   float64\n",
      " 4   FGM          8000 non-null   float64\n",
      " 5   FGA          8000 non-null   float64\n",
      " 6   FG%          8000 non-null   float64\n",
      " 7   3P Made      8000 non-null   float64\n",
      " 8   3PA          8000 non-null   float64\n",
      " 9   3P%          8000 non-null   float64\n",
      " 10  FTM          8000 non-null   float64\n",
      " 11  FTA          8000 non-null   float64\n",
      " 12  FT%          8000 non-null   float64\n",
      " 13  OREB         8000 non-null   float64\n",
      " 14  DREB         8000 non-null   float64\n",
      " 15  REB          8000 non-null   float64\n",
      " 16  AST          8000 non-null   float64\n",
      " 17  STL          8000 non-null   float64\n",
      " 18  BLK          8000 non-null   float64\n",
      " 19  TOV          8000 non-null   float64\n",
      " 20  TARGET_5Yrs  8000 non-null   int64  \n",
      "dtypes: float64(18), int64(3)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Display the summary of columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the summary above, none of the columns in dataframe has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dimensions(shape) of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7798.50000</td>\n",
       "      <td>62.777875</td>\n",
       "      <td>18.576662</td>\n",
       "      <td>7.267088</td>\n",
       "      <td>2.807037</td>\n",
       "      <td>6.231212</td>\n",
       "      <td>44.608900</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>19.583700</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>1.947788</td>\n",
       "      <td>71.365825</td>\n",
       "      <td>1.077838</td>\n",
       "      <td>2.168500</td>\n",
       "      <td>3.245300</td>\n",
       "      <td>1.624513</td>\n",
       "      <td>0.648687</td>\n",
       "      <td>0.245212</td>\n",
       "      <td>1.257763</td>\n",
       "      <td>0.833625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>17.118774</td>\n",
       "      <td>8.935263</td>\n",
       "      <td>4.318732</td>\n",
       "      <td>1.693373</td>\n",
       "      <td>3.584559</td>\n",
       "      <td>6.155453</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>1.060964</td>\n",
       "      <td>16.003155</td>\n",
       "      <td>0.926153</td>\n",
       "      <td>1.252352</td>\n",
       "      <td>10.430447</td>\n",
       "      <td>0.785670</td>\n",
       "      <td>1.392224</td>\n",
       "      <td>2.085154</td>\n",
       "      <td>1.355986</td>\n",
       "      <td>0.407626</td>\n",
       "      <td>0.821037</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.372440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3799.00000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>-38.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5798.75000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7798.50000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9798.25000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11798.00000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>168.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id           GP          MIN          PTS          FGM  \\\n",
       "count   8000.00000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean    7798.50000    62.777875    18.576662     7.267088     2.807037   \n",
       "std     2309.54541    17.118774     8.935263     4.318732     1.693373   \n",
       "min     3799.00000    -8.000000     2.900000     0.800000     0.300000   \n",
       "25%     5798.75000    51.000000    12.000000     4.100000     1.600000   \n",
       "50%     7798.50000    63.000000    16.800000     6.300000     2.400000   \n",
       "75%     9798.25000    74.000000    23.500000     9.500000     3.700000   \n",
       "max    11798.00000   123.000000    73.800000    34.200000    13.100000   \n",
       "\n",
       "               FGA          FG%      3P Made          3PA          3P%  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      6.231212    44.608900     0.264525     0.816562    19.583700   \n",
       "std       3.584559     6.155453     0.384093     1.060964    16.003155   \n",
       "min       0.800000    21.300000    -1.100000    -3.100000   -38.500000   \n",
       "25%       3.600000    40.400000     0.000000     0.100000     8.400000   \n",
       "50%       5.400000    44.400000     0.300000     0.800000    19.500000   \n",
       "75%       8.100000    48.700000     0.500000     1.500000    30.600000   \n",
       "max      28.900000    67.200000     1.700000     4.700000    82.100000   \n",
       "\n",
       "               FTM          FTA          FT%         OREB         DREB  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      1.392525     1.947788    71.365825     1.077838     2.168500   \n",
       "std       0.926153     1.252352    10.430447     0.785670     1.392224   \n",
       "min       0.000000     0.000000   -13.300000     0.000000     0.200000   \n",
       "25%       0.700000     1.000000    65.000000     0.500000     1.100000   \n",
       "50%       1.200000     1.700000    71.400000     0.900000     1.900000   \n",
       "75%       1.900000     2.600000    77.500000     1.500000     2.900000   \n",
       "max       8.100000    11.100000   168.900000     5.500000    11.000000   \n",
       "\n",
       "               REB          AST          STL          BLK          TOV  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      3.245300     1.624513     0.648687     0.245212     1.257763   \n",
       "std       2.085154     1.355986     0.407626     0.821037     0.723270   \n",
       "min       0.300000     0.000000     0.000000   -17.900000     0.100000   \n",
       "25%       1.700000     0.700000     0.300000     0.100000     0.700000   \n",
       "50%       2.800000     1.300000     0.600000     0.200000     1.100000   \n",
       "75%       4.300000     2.200000     0.900000     0.400000     1.600000   \n",
       "max      15.900000    12.800000     3.600000    18.900000     5.300000   \n",
       "\n",
       "       TARGET_5Yrs  \n",
       "count  8000.000000  \n",
       "mean      0.833625  \n",
       "std       0.372440  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unreasonable data based on descriptive summary**\n",
    "- Games played cannot be negative\n",
    "- 3P, 3PA and 3P% Made cannot be negative\n",
    "- FT% can not be negative and cannot be over 100%\n",
    "- BLK can not be negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Split Train and Test Sets for Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data and save it into a variable data_cleaned\n",
    "data_cleaned=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the id column\n",
    "data_cleaned.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column 'TARGET_5Yrs' and save it into variable called target\n",
    "target=data_cleaned.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function scaler_split_train_test from data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the scaler data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val=split_train_test(df=data_cleaned,target=target,test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function save_sets from sets and save the sets into the folder data/processed\n",
    "from src.data.sets import save_sets\n",
    "save_sets(X_train, y_train, X_val, y_val, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function load_sets from sets and load the sets from data/processed\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statistics\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mode of the target variable from the training set\n",
    "y_mode=mode(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array called y_base of dimensions (len(y_train), 1) filled with the mode value\n",
    "y_base=np.full((len(y_train),1),y_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Training: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Import the function print_class_perf from models.performance and display the ROC-AUC score\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_train,y_base,set_name='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lazypredict package\n",
    "import lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LazyClassifier from lazypredict.Supervised\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:14<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit the Lazyclassifier model based on train set and predict the validation set\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "NearestCentroid                    0.59               0.64     0.64      0.64   \n",
       "GaussianNB                         0.58               0.63     0.63      0.64   \n",
       "Perceptron                         0.71               0.63     0.63      0.74   \n",
       "BernoulliNB                        0.64               0.63     0.63      0.68   \n",
       "PassiveAggressiveClassifier        0.70               0.60     0.60      0.73   \n",
       "QuadraticDiscriminantAnalysis      0.77               0.60     0.60      0.77   \n",
       "DecisionTreeClassifier             0.74               0.55     0.55      0.75   \n",
       "BaggingClassifier                  0.81               0.54     0.54      0.78   \n",
       "KNeighborsClassifier               0.82               0.54     0.54      0.78   \n",
       "LabelSpreading                     0.75               0.54     0.54      0.75   \n",
       "LabelPropagation                   0.75               0.53     0.53      0.75   \n",
       "ExtraTreeClassifier                0.72               0.53     0.53      0.73   \n",
       "LGBMClassifier                     0.83               0.52     0.52      0.78   \n",
       "RandomForestClassifier             0.84               0.52     0.52      0.78   \n",
       "XGBClassifier                      0.81               0.52     0.52      0.77   \n",
       "AdaBoostClassifier                 0.84               0.52     0.52      0.78   \n",
       "ExtraTreesClassifier               0.84               0.52     0.52      0.78   \n",
       "LinearDiscriminantAnalysis         0.84               0.52     0.52      0.78   \n",
       "CalibratedClassifierCV             0.84               0.51     0.51      0.77   \n",
       "LogisticRegression                 0.83               0.51     0.51      0.77   \n",
       "DummyClassifier                    0.84               0.50     0.50      0.77   \n",
       "SGDClassifier                      0.84               0.50     0.50      0.77   \n",
       "SVC                                0.84               0.50     0.50      0.77   \n",
       "RidgeClassifier                    0.84               0.50     0.50      0.77   \n",
       "RidgeClassifierCV                  0.84               0.50     0.50      0.77   \n",
       "LinearSVC                          0.84               0.50     0.50      0.77   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "NearestCentroid                      0.01  \n",
       "GaussianNB                           0.02  \n",
       "Perceptron                           0.02  \n",
       "BernoulliNB                          0.02  \n",
       "PassiveAggressiveClassifier          0.02  \n",
       "QuadraticDiscriminantAnalysis        0.02  \n",
       "DecisionTreeClassifier               0.09  \n",
       "BaggingClassifier                    0.48  \n",
       "KNeighborsClassifier                 0.15  \n",
       "LabelSpreading                       3.67  \n",
       "LabelPropagation                     2.32  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "LGBMClassifier                       0.19  \n",
       "RandomForestClassifier               1.22  \n",
       "XGBClassifier                        0.39  \n",
       "AdaBoostClassifier                   0.37  \n",
       "ExtraTreesClassifier                 0.72  \n",
       "LinearDiscriminantAnalysis           0.05  \n",
       "CalibratedClassifierCV               1.80  \n",
       "LogisticRegression                   0.08  \n",
       "DummyClassifier                      0.01  \n",
       "SGDClassifier                        0.06  \n",
       "SVC                                  2.43  \n",
       "RidgeClassifier                      0.02  \n",
       "RidgeClassifierCV                    0.03  \n",
       "LinearSVC                            0.47  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the metrics for different classifiers\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lazypredict_raw.joblib']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Import dump from joblib and save the fitted model into the folder models as a file called lazypredict_cleaned\n",
    "from joblib import dump \n",
    "\n",
    "dump(clf,  '../models/lazypredict_raw.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data and save it into a variable data_cleaned\n",
    "data_cleaned=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the id column\n",
    "data_cleaned.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows where Games played are below or equal to 0\n",
    "len(data_cleaned[(data_cleaned['GP']<=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the small number, remove the 2 records when the column Games played is negative\n",
    "data_cleaned.drop(data_cleaned[data_cleaned['GP']<=0].index,inplace=True)\n",
    "\n",
    "# Method 2\n",
    "# data_cleaned=data_cleaned[(data_cleaned['GP']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1628 rows where '3P Made' column is negative.\n",
      "There are 1657 rows where '3PA' column is negative.\n",
      "There are 878 rows where '3P%' column is negative.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows where the columns of 3P Made, 3PA and 3P% are negative\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['3P Made']<0])} rows where '3P Made' column is negative.\")\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['3PA']<0])} rows where '3PA' column is negative.\")\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['3P%']<0])} rows where '3P%' column is negative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the significant number of rows, the columns of '3P Made', '3PA' and '3P%' are removed from the dataset\n",
    "data_cleaned.drop(['3P Made','3PA','3P%'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 rows where 'FT%' column is negative.\n",
      "There are 58 rows where 'FT%' column is over 100%.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows where FT% is negative or over 100%\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['FT%']<0])} rows where 'FT%' column is negative.\")\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['FT%']>100])} rows where 'FT%' column is over 100%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the small number, remove the records that FT% is negative or over 100%\n",
    "data_cleaned.drop(data_cleaned[(data_cleaned['FT%']<0)|(data_cleaned['FT%']>100)].index,inplace=True)\n",
    "\n",
    "# Method 2\n",
    "# data_cleaned=data_cleaned[(data_cleaned['FT%']>=0)&(data_cleaned['FT%']<=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1029 rows where 'BLK' column is negative.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows where BLK is negative\n",
    "print(f\"There are {len(data_cleaned[data_cleaned['BLK']<0])} rows where 'BLK' column is negative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the significant number of rows, the column of 'BLK' is removed from the dataset\n",
    "data_cleaned.drop(['BLK'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the whether there are duplicate rows\n",
    "sum(data_cleaned.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7939, 16)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display number of rows and columns after data cleansing\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column 'TARGET_5Yrs' and save it into variable called target\n",
    "target=data_cleaned.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and apply the scaling on data_cleaned\n",
    "data_cleaned=scaler.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dump from joblib\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler.joblib']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler into the folder models and call the file scaler.joblib\n",
    "dump(scaler, '../models/scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function scaler_split_train_test from data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sys.path[1]\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the scaler data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val=split_train_test(df=data_cleaned,target=target,test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function save_sets from sets and save the sets into the folder data/processed\n",
    "from src.data.sets import save_sets\n",
    "save_sets(X_train, y_train, X_val, y_val, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function load_sets from sets and load the sets from data/processed\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classification Models with Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lazypredict package\n",
    "import lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LazyClassifier from lazypredict.Supervised\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:13<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit the Lazyclassifier model based on train set and predict the validation set\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "NearestCentroid                    0.59               0.63     0.63      0.65   \n",
       "QuadraticDiscriminantAnalysis      0.74               0.63     0.63      0.76   \n",
       "GaussianNB                         0.57               0.62     0.62      0.63   \n",
       "BernoulliNB                        0.65               0.62     0.62      0.69   \n",
       "Perceptron                         0.68               0.61     0.61      0.72   \n",
       "ExtraTreeClassifier                0.75               0.55     0.55      0.75   \n",
       "LabelPropagation                   0.77               0.54     0.54      0.76   \n",
       "KNeighborsClassifier               0.82               0.54     0.54      0.79   \n",
       "LabelSpreading                     0.77               0.54     0.54      0.76   \n",
       "BaggingClassifier                  0.81               0.54     0.54      0.78   \n",
       "DecisionTreeClassifier             0.73               0.53     0.53      0.74   \n",
       "XGBClassifier                      0.82               0.52     0.52      0.78   \n",
       "AdaBoostClassifier                 0.84               0.51     0.51      0.78   \n",
       "LinearDiscriminantAnalysis         0.84               0.51     0.51      0.78   \n",
       "RandomForestClassifier             0.84               0.51     0.51      0.78   \n",
       "LGBMClassifier                     0.83               0.51     0.51      0.78   \n",
       "ExtraTreesClassifier               0.84               0.51     0.51      0.78   \n",
       "LogisticRegression                 0.84               0.51     0.51      0.78   \n",
       "CalibratedClassifierCV             0.84               0.51     0.51      0.78   \n",
       "DummyClassifier                    0.84               0.50     0.50      0.77   \n",
       "SGDClassifier                      0.84               0.50     0.50      0.77   \n",
       "SVC                                0.84               0.50     0.50      0.77   \n",
       "RidgeClassifier                    0.84               0.50     0.50      0.77   \n",
       "RidgeClassifierCV                  0.84               0.50     0.50      0.77   \n",
       "LinearSVC                          0.84               0.50     0.50      0.77   \n",
       "PassiveAggressiveClassifier        0.68               0.44     0.44      0.69   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "NearestCentroid                      0.01  \n",
       "QuadraticDiscriminantAnalysis        0.03  \n",
       "GaussianNB                           0.01  \n",
       "BernoulliNB                          0.01  \n",
       "Perceptron                           0.02  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "LabelPropagation                     1.65  \n",
       "KNeighborsClassifier                 0.23  \n",
       "LabelSpreading                       3.18  \n",
       "BaggingClassifier                    0.37  \n",
       "DecisionTreeClassifier               0.06  \n",
       "XGBClassifier                        0.37  \n",
       "AdaBoostClassifier                   0.30  \n",
       "LinearDiscriminantAnalysis           0.04  \n",
       "RandomForestClassifier               1.04  \n",
       "LGBMClassifier                       0.18  \n",
       "ExtraTreesClassifier                 0.53  \n",
       "LogisticRegression                   0.06  \n",
       "CalibratedClassifierCV               1.41  \n",
       "DummyClassifier                      0.01  \n",
       "SGDClassifier                        0.04  \n",
       "SVC                                  2.86  \n",
       "RidgeClassifier                      0.02  \n",
       "RidgeClassifierCV                    0.02  \n",
       "LinearSVC                            0.53  \n",
       "PassiveAggressiveClassifier          0.02  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the metrics of classifiers\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lazypredict_cleaned.joblib']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Import dump from joblib and save the fitted model into the folder models as a file called lazypredict_cleaned\n",
    "from joblib import dump \n",
    "\n",
    "dump(clf,  '../models/lazypredict_cleaned.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomForestClassifier class called rf with a random state=8\n",
    "rf = RandomForestClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomForest model with train data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 8,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rf_original_default.joblib']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump \n",
    "\n",
    "dump(rf,  '../models/rf_original_default.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability when target=1\n",
    "probs_train=rf.predict_proba(X_train)[:,1]\n",
    "probs_val=rf.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Training: 1.0\n",
      "ROC AUC Score Validation: 0.6740837144920558\n"
     ]
    }
   ],
   "source": [
    "# Import the function print_class_perf from models.performance and display the ROC-AUC score\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_actuals=y_train, y_probs=probs_train,set_name='Training')\n",
    "print_class_perf(y_actuals=y_val, y_probs=probs_val,set_name='Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the roc_auc_score for validation data based on initial model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_roc_auc = roc_auc_score(y_val, rf.predict_proba(X_val)[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_val, rf.predict_proba(X_val)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5087c292a60e433539a3ea1db33a548e8b6d2b5fd0ec051734d3134be8f1ad1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
